# Uncertainty-aware Smart Labelling Tool and U-Net Suite

## Overview
This repository provides two major components:

1. **Deep Learning Suite** – TensorFlow-based training and inference utilities centred on U-Net segmentation models for high-resolution medical image analysis.
2. **Smart Labelling System** – a PyQt5 application that streamlines manual annotation using predictions and uncertainty estimates generated by the models.

**Note:** This project is not production-ready and remains a proof of concept. Software behaviour may change between versions.

![Project Screenshot](GUI/assets/AL%20Workflow.png)

The goal of this project was to develop a system that leverages uncertainty measures derived from uncertainty-aware CNN segmentation models for smart point-counting annotation of (though not limited to) Colorectal Cancer histopathology images. The motivation was to experiment with deep learning model-adaptation strategies in settings with low annotation budgets, such as with medical imaging. The typical workflow involves training an initial segmentation model on a single data domain, performing inference to generate probability maps and uncertainties, and then using the graphical interface to rapidly label point annotations guided by the uncertainty scores. The new annotations can be fed back into the training scripts to iteratively improve deep learning models.



## Core Components and Features
### Attention U-Net
- Decoder includes optional attention gates and group normalisation for stable training.
- Mixed precision and distributed training via `MirroredStrategy`.
- YAML configuration for architecture and data parameters.

### Smart Labelling System
- Opens HDF5 or SQLite databases produced by the inference tools.
- Clusters candidate points and presents them in an interactive grid for fast labelling.
- Propagates uncertainty scores as labels are applied so that recommendations update in real time.
- Autosave, project management, and preview dialogues to inspect full-size images with the new annotations overlayed.
- Export of labelled points to JSON for further model training or analysis.

![Project Screenshot](GUI/assets/Manual%20Labelling%20a%20Crop.png)

## Getting Started
### Environment
Install the dependencies with Conda:
```bash
conda env create -f environment.yml
```
Activate the environment with `conda activate SLT`.

### Training a Model
Edit `configurations/configuration.yaml` to match your dataset. Start training with:
```bash
python DeepLearning/training/main.py --config configurations/configuration.yaml
```
Checkpoints and logs will be written to the directory specified in the configuration file.

### Running Inference
The scripts under `DeepLearning/inference/` generate prediction logits and uncertainty measures that the GUI can read. See `main_infer.py` for a minimal example.

### Launching the Smart Labelling Tool
Run the GUI from the repository root:
```bash
python gui_main.py
```
A start-up dialogue allows you to continue a previous session, load an existing project, or create a new one from a predictions database. Label clusters of points and export the results when finished.

Alternatively, you can build a portable .exe using the build_exe.sh script.

## Repository Layout
```
DeepLearning/    – model architectures, training and inference code
GUI/             – PyQt5 smart labelling application
```

## Tests
Unit tests for both components can be executed. These are not extensive, but should help with understanding the core components of the code:
```bash
pytest
```

## Contributing
Follow PEP8 with four spaces per indent and target Python 3.8. Public modules, classes and functions should include docstrings. New GUI features require tests under `GUI/unittests`.

## License
Distributed under the GPL-3.0 License. See the `LICENSE` file for details.

## Authors
Benjamin Isaac Wilson – benjamintaya0111@gmail.com
